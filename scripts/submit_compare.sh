#!/bin/bash
#SBATCH --job-name=neha_compare
#SBATCH --partition=any_cpu
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
#SBATCH --time=00:30:00
#SBATCH --output=logs/compare_%j.out
#SBATCH --error=logs/compare_%j.err

echo "--- Starting pTempest Comparison on $(hostname) ---"

# --- 0. LOAD CONFIGURATION ---
source ./user_config_slurm.sh

# --- 1. DEFINE PATHS AND SCRATCH DIRECTORY ---
SCRDIR="/scr/${SLURM_JOB_ID}"
mkdir -p "$SCRDIR"

# On exit, copy back results and cleanup
trap 'rsync -av "$SCRDIR"/final_results_plots/ "$PROJECT_HOME"/final_results_plots/ 2>/dev/null || true; rm -rf "$SCRDIR"' EXIT

# --- 2. PREPARE DIRECTORIES ---
mkdir -p "$PROJECT_HOME"/logs
mkdir -p "$PROJECT_HOME"/final_results_plots

# --- 3. COPY FILES TO SCRATCH ---
cp "$PROJECT_HOME"/compare_results.jl "$SCRDIR"/
# We need best_parameters.csv (generated by collate)
cp "$PROJECT_HOME"/best_parameters.csv "$SCRDIR"/
# We assume STAT_models is available or copy it?
# It's better to read STAT_models from PROJECT_HOME directly if it's large, 
# OR copy the specific pTempest files needed.
# Script expects relative path: STAT_models/pSTAT_mechanistic_model/...
mkdir -p "$SCRDIR"/STAT_models
cp -r "$PROJECT_HOME"/STAT_models/pSTAT_mechanistic_model "$SCRDIR"/STAT_models/
cp "$PROJECT_HOME"/variable_JAK_STAT_SOCS_degrad_model.net "$SCRDIR"/

# --- 4. MOVE INTO SCRATCH ---
cd "$SCRDIR"

# --- 5. RUN SCRIPT ---
julia --project="$IL6_HOME/bngl_julia" --sysimage="$IL6_HOME/SysImage/bngl_full.so" \
    compare_results.jl

echo "--- Comparison Finished ---"
